{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48e00c6-607f-4265-9d99-6cd044b02dbe",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2caa895f-d172-40b0-88fe-13c3782dc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83bd9d-77fe-47f4-a1a5-d0c287de357a",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72655c72-3388-4ea6-80fe-a59ca93fd392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 9]\n",
      " [1 5]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "# Each row = [hours studied, hours slept]\n",
    "X = np.array([\n",
    "    [2, 9],\n",
    "    [1, 5],\n",
    "    [3, 6]\n",
    "])\n",
    "\n",
    "# Labels: 1 = pass, 0 = fail\n",
    "y = np.array([\n",
    "    [1],\n",
    "    [0],\n",
    "    [1]\n",
    "])\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ec09d-11cc-437f-b226-3e11ace06e2c",
   "metadata": {},
   "source": [
    "## Normalize Data\n",
    "\n",
    "- Neural networks learn better when inputs are between 0 and 1.\n",
    "- This scales down the values to that range (e.g. 5 becomes 0.5 if max is 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf6eaf-e38e-4c46-88e2-3929c37ecf1c",
   "metadata": {},
   "source": [
    "X = X / np.amax(X, axis=0)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ac15c-d138-4abc-b70c-30d0b9cab883",
   "metadata": {},
   "source": [
    "## Initialize Weights Randomly\n",
    "\n",
    "- Each input feature needs a weight (importance).\n",
    "- The network \"learns\" the best weights over time.\n",
    "- We start with random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae7cfaa7-1c14-450a-a61f-91aa73026d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012]\n",
      " [0.95071431]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  # for consistent results\n",
    "weights = np.random.rand(2, 1)\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90d2ed-d358-489b-a79d-dc71822eb536",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "\n",
    "- Without this, the output could be any number (like 14 or -7).\n",
    "- Sigmoid \"squashes\" the output between 0 and 1 this is perfect for probabilities\n",
    "- It's like: \"how confident is the model that this person will pass?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "716408e4-70fa-4e52-abd3-606c1042f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d518e-7dce-478c-9b4e-f13bff2687a5",
   "metadata": {},
   "source": [
    "## Forward Pass (Prediction)\n",
    "\n",
    "This simulates a single layer neural network:\n",
    "\n",
    "- Multiply inputs by weights (like: 5 hrs * 0.4 + 6 hrs * 0.6)\n",
    "- Applying sigmoid, e.g., 0.91 -> 91% chance of passing\n",
    "- Dot products or matrix multiplication in ML are usually computing how strongly inputs activate a neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "951c7de2-e752-4ab2-9b7a-8e8bbd818568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    z = np.dot(X, weights)     # linear part: inputs Ã— weights\n",
    "    output = sigmoid(z)        # apply non-linear activation\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bbfe11b-f9a3-411b-956e-34182838dc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99990909]\n",
      " [0.99410719]\n",
      " [0.99891805]]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(X, weights)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a3360f-a741-4585-afac-4b391b611d3e",
   "metadata": {},
   "source": [
    "## Loss Function (MSE)\n",
    "\n",
    "- Measures how bad the model's predictions are.\n",
    "- Smaller value = better prediction.\n",
    "- This helps guide the learning process in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fc7318f-b0b2-46e1-8cfa-1a1e92e26096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3294167597215201\n"
     ]
    }
   ],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "loss = mean_squared_error(y, predictions)\n",
    "print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e233dbc-7d21-435a-b022-f64cc9e7e2eb",
   "metadata": {},
   "source": [
    "## Backward Pass & Weight Update\n",
    "\n",
    "- Right now, the model uses random weights.\n",
    "- In training, it compares predictions with actual answers and adjusts the weights to get better.\n",
    "- That process is called backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62e26edb-e58b-4748-b81f-846b7f886cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(1000):\n",
    "    z = np.dot(X, weights)\n",
    "    output = sigmoid(z)\n",
    "\n",
    "    error = y - output\n",
    "    adjustments = error * sigmoid_derivative(output)\n",
    "\n",
    "    weights += np.dot(X.T, adjustments) * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97191a83-3a2f-4c9a-9405-7c3dad9da82b",
   "metadata": {},
   "source": [
    "## Output Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1aa9411b-3924-403a-9afc-e9c840912545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97380948]]\n"
     ]
    }
   ],
   "source": [
    "# Example prediction for one student\n",
    "student = np.array([5, 6]) / np.amax(X, axis=0)\n",
    "result = predict(student.reshape(1, -1), weights)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a98cca-9efc-404d-a97e-5b076a2f1e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
